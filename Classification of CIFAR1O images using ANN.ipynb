{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c8cbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2df9beda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dc330bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0861bf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape is: (50000, 32, 32, 3)\n",
      "y_train shape is: (50000, 1)\n",
      "x_test shape is: (10000, 32, 32, 3)\n",
      "y_test shape is: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"{} shape is: {}\".format(\"x_train\", x_train.shape))\n",
    "print(\"{} shape is: {}\".format(\"y_train\", y_train.shape))\n",
    "print(\"{} shape is: {}\".format(\"x_test\", x_test.shape))\n",
    "print(\"{} shape is: {}\".format(\"y_test\", y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d8c3543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 59,  62,  63],\n",
       "        [ 43,  46,  45],\n",
       "        [ 50,  48,  43],\n",
       "        ...,\n",
       "        [158, 132, 108],\n",
       "        [152, 125, 102],\n",
       "        [148, 124, 103]],\n",
       "\n",
       "       [[ 16,  20,  20],\n",
       "        [  0,   0,   0],\n",
       "        [ 18,   8,   0],\n",
       "        ...,\n",
       "        [123,  88,  55],\n",
       "        [119,  83,  50],\n",
       "        [122,  87,  57]],\n",
       "\n",
       "       [[ 25,  24,  21],\n",
       "        [ 16,   7,   0],\n",
       "        [ 49,  27,   8],\n",
       "        ...,\n",
       "        [118,  84,  50],\n",
       "        [120,  84,  50],\n",
       "        [109,  73,  42]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[208, 170,  96],\n",
       "        [201, 153,  34],\n",
       "        [198, 161,  26],\n",
       "        ...,\n",
       "        [160, 133,  70],\n",
       "        [ 56,  31,   7],\n",
       "        [ 53,  34,  20]],\n",
       "\n",
       "       [[180, 139,  96],\n",
       "        [173, 123,  42],\n",
       "        [186, 144,  30],\n",
       "        ...,\n",
       "        [184, 148,  94],\n",
       "        [ 97,  62,  34],\n",
       "        [ 83,  53,  34]],\n",
       "\n",
       "       [[177, 144, 116],\n",
       "        [168, 129,  94],\n",
       "        [179, 142,  87],\n",
       "        ...,\n",
       "        [216, 184, 140],\n",
       "        [151, 118,  84],\n",
       "        [123,  92,  72]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f942d72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       [4],\n",
       "       [1],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c703037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[4563])\n",
    "y_train[4563]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85162f36",
   "metadata": {},
   "source": [
    "## Scalling the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94457d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train =  x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8217c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.23137255, 0.24313725, 0.24705882],\n",
       "        [0.16862745, 0.18039216, 0.17647059],\n",
       "        [0.19607843, 0.18823529, 0.16862745],\n",
       "        ...,\n",
       "        [0.61960784, 0.51764706, 0.42352941],\n",
       "        [0.59607843, 0.49019608, 0.4       ],\n",
       "        [0.58039216, 0.48627451, 0.40392157]],\n",
       "\n",
       "       [[0.0627451 , 0.07843137, 0.07843137],\n",
       "        [0.        , 0.        , 0.        ],\n",
       "        [0.07058824, 0.03137255, 0.        ],\n",
       "        ...,\n",
       "        [0.48235294, 0.34509804, 0.21568627],\n",
       "        [0.46666667, 0.3254902 , 0.19607843],\n",
       "        [0.47843137, 0.34117647, 0.22352941]],\n",
       "\n",
       "       [[0.09803922, 0.09411765, 0.08235294],\n",
       "        [0.0627451 , 0.02745098, 0.        ],\n",
       "        [0.19215686, 0.10588235, 0.03137255],\n",
       "        ...,\n",
       "        [0.4627451 , 0.32941176, 0.19607843],\n",
       "        [0.47058824, 0.32941176, 0.19607843],\n",
       "        [0.42745098, 0.28627451, 0.16470588]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.81568627, 0.66666667, 0.37647059],\n",
       "        [0.78823529, 0.6       , 0.13333333],\n",
       "        [0.77647059, 0.63137255, 0.10196078],\n",
       "        ...,\n",
       "        [0.62745098, 0.52156863, 0.2745098 ],\n",
       "        [0.21960784, 0.12156863, 0.02745098],\n",
       "        [0.20784314, 0.13333333, 0.07843137]],\n",
       "\n",
       "       [[0.70588235, 0.54509804, 0.37647059],\n",
       "        [0.67843137, 0.48235294, 0.16470588],\n",
       "        [0.72941176, 0.56470588, 0.11764706],\n",
       "        ...,\n",
       "        [0.72156863, 0.58039216, 0.36862745],\n",
       "        [0.38039216, 0.24313725, 0.13333333],\n",
       "        [0.3254902 , 0.20784314, 0.13333333]],\n",
       "\n",
       "       [[0.69411765, 0.56470588, 0.45490196],\n",
       "        [0.65882353, 0.50588235, 0.36862745],\n",
       "        [0.70196078, 0.55686275, 0.34117647],\n",
       "        ...,\n",
       "        [0.84705882, 0.72156863, 0.54901961],\n",
       "        [0.59215686, 0.4627451 , 0.32941176],\n",
       "        [0.48235294, 0.36078431, 0.28235294]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c21008d",
   "metadata": {},
   "source": [
    "## One hot encoding the lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cda52c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categoricals = keras.utils.to_categorical(y_train, num_classes=10, dtype='float32')\n",
    "y_test_categorical = keras.utils.to_categorical(\n",
    "    y_test, num_classes=10, dtype='float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0d9c56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4e29918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_categoricals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d40ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(32,32,3)),\n",
    "    keras.layers.Dense(3000, activation='relu'),\n",
    "    keras.layers.Dense(1500, activation= 'relu'),\n",
    "    keras.layers.Dense(10, activation= 'sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3254ad65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 362s 231ms/step - loss: 1.8908 - accuracy: 0.3259\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 361s 231ms/step - loss: 1.6647 - accuracy: 0.4030\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 357s 228ms/step - loss: 1.5915 - accuracy: 0.4294\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 355s 227ms/step - loss: 1.5444 - accuracy: 0.4476\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 360s 230ms/step - loss: 1.5063 - accuracy: 0.4601\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 356s 228ms/step - loss: 1.4817 - accuracy: 0.4682\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 355s 227ms/step - loss: 1.4584 - accuracy: 0.4764\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 354s 227ms/step - loss: 1.4335 - accuracy: 0.4835\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 357s 228ms/step - loss: 1.4131 - accuracy: 0.4917\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 356s 228ms/step - loss: 1.3911 - accuracy: 0.5043\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 357s 229ms/step - loss: 1.3770 - accuracy: 0.5051\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 349s 223ms/step - loss: 1.3596 - accuracy: 0.5124\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 355s 227ms/step - loss: 1.3404 - accuracy: 0.5183\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 355s 227ms/step - loss: 1.3275 - accuracy: 0.5232\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 355s 227ms/step - loss: 1.3140 - accuracy: 0.5303\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 356s 228ms/step - loss: 1.3014 - accuracy: 0.5334\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 356s 227ms/step - loss: 1.2892 - accuracy: 0.5373\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 355s 227ms/step - loss: 1.2754 - accuracy: 0.5411\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 356s 228ms/step - loss: 1.2650 - accuracy: 0.5449\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 356s 228ms/step - loss: 1.2527 - accuracy: 0.5508\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 357s 228ms/step - loss: 1.2427 - accuracy: 0.5534\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 358s 229ms/step - loss: 1.2337 - accuracy: 0.5569\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 366s 234ms/step - loss: 1.2277 - accuracy: 0.5568\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 365s 234ms/step - loss: 1.2141 - accuracy: 0.5641\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 369s 236ms/step - loss: 1.2037 - accuracy: 0.5658\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 342s 219ms/step - loss: 1.1939 - accuracy: 0.5708\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 365s 234ms/step - loss: 1.1858 - accuracy: 0.5742\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 378s 242ms/step - loss: 1.1753 - accuracy: 0.5773\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 375s 240ms/step - loss: 1.1743 - accuracy: 0.5778\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 390s 250ms/step - loss: 1.1646 - accuracy: 0.5807\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 379s 243ms/step - loss: 1.1528 - accuracy: 0.5856\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 390s 250ms/step - loss: 1.1455 - accuracy: 0.5867\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 376s 240ms/step - loss: 1.1359 - accuracy: 0.5896\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 327s 209ms/step - loss: 1.1365 - accuracy: 0.5908\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 324s 207ms/step - loss: 1.1249 - accuracy: 0.5931\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 326s 208ms/step - loss: 1.1205 - accuracy: 0.5957\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 326s 209ms/step - loss: 1.1100 - accuracy: 0.5994\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 328s 210ms/step - loss: 1.1078 - accuracy: 0.6001\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 316s 202ms/step - loss: 1.0973 - accuracy: 0.6027\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 319s 204ms/step - loss: 1.0930 - accuracy: 0.6056\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 319s 204ms/step - loss: 1.0888 - accuracy: 0.6071\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 323s 206ms/step - loss: 1.0803 - accuracy: 0.6098\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 323s 207ms/step - loss: 1.0766 - accuracy: 0.6127\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 323s 207ms/step - loss: 1.0750 - accuracy: 0.6129\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 322s 206ms/step - loss: 1.0645 - accuracy: 0.6129\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 322s 206ms/step - loss: 1.0595 - accuracy: 0.6167\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 323s 206ms/step - loss: 1.0504 - accuracy: 0.6199\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 324s 207ms/step - loss: 1.0490 - accuracy: 0.6200\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 324s 207ms/step - loss: 1.0362 - accuracy: 0.6236\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 323s 207ms/step - loss: 1.0413 - accuracy: 0.6244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19fc028ea90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(x_train, y_train_categoricals, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee552cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 1.7598 - accuracy: 0.4815\n",
      "313/313 [==============================] - 4s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test_categorical)\n",
    "y_predicted =  model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be29641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = keras.Sequential([\n",
    "    ##Convolution Layers:\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape= (32,32,3)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    ##DenseLayers:\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1000, activation='relu'),\n",
    "    keras.layers.Dropout(0.5), #Dropout regularization\n",
    "    keras.layers.Dense(250, activation= 'relu'),\n",
    "    keras.layers.Dense(10, activation= 'softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac2ce44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 1.4799 - accuracy: 0.4614\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 81s 52ms/step - loss: 1.1529 - accuracy: 0.5929\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 1.0179 - accuracy: 0.6416\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.9234 - accuracy: 0.6735\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 45s 29ms/step - loss: 0.8540 - accuracy: 0.7005\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 58s 37ms/step - loss: 0.7969 - accuracy: 0.7192\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.7357 - accuracy: 0.7395\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.6856 - accuracy: 0.7578\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 73s 47ms/step - loss: 0.6363 - accuracy: 0.7721\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 0.5978 - accuracy: 0.7861\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.5588 - accuracy: 0.7992\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.5283 - accuracy: 0.8127\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 72s 46ms/step - loss: 0.4972 - accuracy: 0.8246\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.4670 - accuracy: 0.8313\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 49s 32ms/step - loss: 0.4445 - accuracy: 0.8429\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.4240 - accuracy: 0.8477\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.4074 - accuracy: 0.8562\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.3851 - accuracy: 0.8629\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 74s 47ms/step - loss: 0.3742 - accuracy: 0.8670\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 74s 47ms/step - loss: 0.3595 - accuracy: 0.8727\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 74s 47ms/step - loss: 0.3501 - accuracy: 0.8766\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 71s 46ms/step - loss: 0.3331 - accuracy: 0.8818\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 75s 48ms/step - loss: 0.3267 - accuracy: 0.8839\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 72s 46ms/step - loss: 0.3160 - accuracy: 0.8888\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.3064 - accuracy: 0.8919\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.3004 - accuracy: 0.8954\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.2900 - accuracy: 0.8995\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 57s 36ms/step - loss: 0.2865 - accuracy: 0.9005\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.2741 - accuracy: 0.9057\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.2688 - accuracy: 0.9059\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.2633 - accuracy: 0.9082\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 0.2603 - accuracy: 0.9109\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 57s 37ms/step - loss: 0.2530 - accuracy: 0.9110\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 60s 39ms/step - loss: 0.2444 - accuracy: 0.9156\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 59s 38ms/step - loss: 0.2443 - accuracy: 0.9158\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.2360 - accuracy: 0.9189\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.2314 - accuracy: 0.9219\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.2382 - accuracy: 0.9189\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 0.2233 - accuracy: 0.9239\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 48s 30ms/step - loss: 0.2180 - accuracy: 0.9256\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.2210 - accuracy: 0.9246\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.2180 - accuracy: 0.9264\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.2083 - accuracy: 0.9303\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 0.2139 - accuracy: 0.9271\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.2104 - accuracy: 0.9285\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 0.1988 - accuracy: 0.9323\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.1989 - accuracy: 0.9332\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.2018 - accuracy: 0.9330\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.1939 - accuracy: 0.9340\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.1999 - accuracy: 0.9326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a023bc6d60>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "cnn_model.fit(x_train, y_train_categoricals, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a751bc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 1.2192 - accuracy: 0.7088\n",
      "313/313 [==============================] - 2s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_model.evaluate(x_test, y_test_categorical)\n",
    "y_predicted =  cnn_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9593d53c",
   "metadata": {},
   "source": [
    "#### The training accuracy is much greater tha the test accuracy for about an 23%. It can be understood that model is overfit. As there is no augmented data used for training the model, the model tend to overfit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9db5731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef36a07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02214972, 0.00433534, 0.00268314, 0.19594394, 0.00274738,\n",
       "       0.6526068 , 0.01825264, 0.00122016, 0.09029397, 0.00976688],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02d6114c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 8, 8, 0, 6, 6, 3, 6, 3, 1]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = [np.argmax(i) for i in y_predicted]\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8980501d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 8, ..., 5, 1, 7], dtype=uint8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_reshaped = y_test.reshape(-1)\n",
    "y_test_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c10759ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1000\n",
      "           1       0.81      0.85      0.83      1000\n",
      "           2       0.68      0.51      0.58      1000\n",
      "           3       0.48      0.48      0.48      1000\n",
      "           4       0.64      0.69      0.67      1000\n",
      "           5       0.59      0.60      0.59      1000\n",
      "           6       0.74      0.83      0.78      1000\n",
      "           7       0.77      0.75      0.76      1000\n",
      "           8       0.82      0.82      0.82      1000\n",
      "           9       0.76      0.82      0.79      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.71     10000\n",
      "weighted avg       0.71      0.71      0.71     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "print(\"Classification Report: \\n\", classification_report(y_test_reshaped, y_pred ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a79970c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
    "                                                 input_shape=(32, \n",
    "                                                              32,\n",
    "                                                              3)),\n",
    "    keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "83ca3141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "cnn_model_aug = keras.Sequential([\n",
    "    \n",
    "    data_augmentation,\n",
    "    \n",
    "    ##Convolution Layers:\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape= (32,32,3)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    ##DenseLayers:\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(3000, activation='relu'),\n",
    "    keras.layers.Dropout(0.5), #Dropout regularization\n",
    "    keras.layers.Dense(800, activation= 'relu'),\n",
    "    keras.layers.Dropout(0.5), #Dropout regularization\n",
    "    keras.layers.Dense(10, activation= 'softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "79112c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "1563/1563 [==============================] - 182s 113ms/step - loss: 1.6822 - accuracy: 0.3711\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 169s 108ms/step - loss: 1.4124 - accuracy: 0.4908\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 183s 117ms/step - loss: 1.2986 - accuracy: 0.5402\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 214s 137ms/step - loss: 1.2361 - accuracy: 0.5642\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 178s 114ms/step - loss: 1.1918 - accuracy: 0.5832\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 149s 95ms/step - loss: 1.1559 - accuracy: 0.5951\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 197s 126ms/step - loss: 1.1269 - accuracy: 0.6067\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 183s 117ms/step - loss: 1.1011 - accuracy: 0.6165\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 147s 94ms/step - loss: 1.0855 - accuracy: 0.6243\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 169s 108ms/step - loss: 1.0708 - accuracy: 0.6269\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 155s 99ms/step - loss: 1.0580 - accuracy: 0.6331\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 138s 88ms/step - loss: 1.0430 - accuracy: 0.6373\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 138s 88ms/step - loss: 1.0287 - accuracy: 0.6439\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 1.0176 - accuracy: 0.6473\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 182s 117ms/step - loss: 1.0069 - accuracy: 0.6501\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 160s 102ms/step - loss: 0.9974 - accuracy: 0.6554\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 166s 106ms/step - loss: 0.9876 - accuracy: 0.6596\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 208s 133ms/step - loss: 0.9848 - accuracy: 0.6587\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 141s 90ms/step - loss: 0.9777 - accuracy: 0.6614\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 152s 97ms/step - loss: 0.9675 - accuracy: 0.6644\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.9672 - accuracy: 0.6668\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 145s 93ms/step - loss: 0.9559 - accuracy: 0.6692\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.9559 - accuracy: 0.6722\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 156s 100ms/step - loss: 0.9597 - accuracy: 0.6708\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 200s 128ms/step - loss: 0.9451 - accuracy: 0.6740\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 164s 105ms/step - loss: 0.9512 - accuracy: 0.6731\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 166s 106ms/step - loss: 0.9425 - accuracy: 0.6764\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 140s 90ms/step - loss: 0.9403 - accuracy: 0.6787\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.9359 - accuracy: 0.6803\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.9303 - accuracy: 0.6813\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.9267 - accuracy: 0.6817\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 153s 98ms/step - loss: 0.9236 - accuracy: 0.6833\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 161s 103ms/step - loss: 0.9303 - accuracy: 0.6819\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 154s 98ms/step - loss: 0.9266 - accuracy: 0.6813\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 163s 104ms/step - loss: 0.9202 - accuracy: 0.6860\n",
      "Epoch 36/50\n",
      "1563/1563 [==============================] - 152s 97ms/step - loss: 0.9154 - accuracy: 0.6850\n",
      "Epoch 37/50\n",
      "1563/1563 [==============================] - 162s 104ms/step - loss: 0.9126 - accuracy: 0.6862\n",
      "Epoch 38/50\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.9122 - accuracy: 0.6867\n",
      "Epoch 39/50\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.9087 - accuracy: 0.6901\n",
      "Epoch 40/50\n",
      "1563/1563 [==============================] - 155s 99ms/step - loss: 0.9069 - accuracy: 0.6876\n",
      "Epoch 41/50\n",
      "1563/1563 [==============================] - 136s 87ms/step - loss: 0.9027 - accuracy: 0.6899\n",
      "Epoch 42/50\n",
      "1563/1563 [==============================] - 150s 96ms/step - loss: 0.9071 - accuracy: 0.6887\n",
      "Epoch 43/50\n",
      "1563/1563 [==============================] - 147s 94ms/step - loss: 0.8998 - accuracy: 0.6921\n",
      "Epoch 44/50\n",
      "1563/1563 [==============================] - 154s 98ms/step - loss: 0.8983 - accuracy: 0.6926\n",
      "Epoch 45/50\n",
      "1563/1563 [==============================] - 161s 103ms/step - loss: 0.8932 - accuracy: 0.6956\n",
      "Epoch 46/50\n",
      "1563/1563 [==============================] - 146s 93ms/step - loss: 0.8996 - accuracy: 0.6921\n",
      "Epoch 47/50\n",
      "1563/1563 [==============================] - 145s 93ms/step - loss: 0.8945 - accuracy: 0.6955\n",
      "Epoch 48/50\n",
      "1563/1563 [==============================] - 143s 92ms/step - loss: 0.8970 - accuracy: 0.6943\n",
      "Epoch 49/50\n",
      "1563/1563 [==============================] - 149s 95ms/step - loss: 0.8902 - accuracy: 0.6956\n",
      "Epoch 50/50\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.8944 - accuracy: 0.6963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a0397acd30>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model_aug.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "cnn_model_aug.fit(x_train, y_train_categoricals, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8d64057d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step - loss: 0.8992 - accuracy: 0.6915\n",
      "313/313 [==============================] - 2s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_model_aug.evaluate(x_test, y_test_categorical)\n",
    "y_predicted =  cnn_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "479201a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1000\n",
      "           1       0.81      0.85      0.83      1000\n",
      "           2       0.68      0.51      0.58      1000\n",
      "           3       0.48      0.48      0.48      1000\n",
      "           4       0.64      0.69      0.67      1000\n",
      "           5       0.59      0.60      0.59      1000\n",
      "           6       0.74      0.83      0.78      1000\n",
      "           7       0.77      0.75      0.76      1000\n",
      "           8       0.82      0.82      0.82      1000\n",
      "           9       0.76      0.82      0.79      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.71      0.71      0.71     10000\n",
      "weighted avg       0.71      0.71      0.71     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "print(\"Classification Report: \\n\", classification_report(y_test_reshaped, y_pred ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880adc8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
